{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Vladyslav Maksyk\"\n",
    "COLLABORATORS = \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dac3401f7e517b1cec72732f9437fb58",
     "grade": false,
     "grade_id": "cell-dd54ad0671f620b9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Machine Learning in Spark\n",
    "\n",
    "Following the evolution of Spark, there are two ways to do Machine Learning on Spark :\n",
    "\n",
    "* MLlib, or `spark.mllib`, was the first ML library implemented in the core Spark library and runs on RDDs. As of today, the library is in maintenance mode, but as we did for RDDs vs DataFrames, it is important that we cover some aspects of the older library. MLlib is also the only library that supports training models for Spark Streaming. \n",
    "* ML, or `spark.ml` is now the primary ML library on Spark, and runs on DataFrames. Its API is close to those of other mainstream librairies like scikit-learn.\n",
    "\n",
    "We will dive into both APIs in this notebook, using the `titanic.csv` file for classification purposes on the `Survived` column.\n",
    "\n",
    "_I think at this point of your career, you all know what the [Titanic dataset](https://www.kaggle.com/c/titanic/data) is..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ba80560f7c7b1b281d9ab2ccdbe4b76",
     "grade": false,
     "grade_id": "cell-1e94907f4239a99c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-0A1DC1R:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>lecture-lyon2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1dc7f324508>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName('lecture-lyon2').setMaster('local')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d56e90c8e0a2f67a92b3eaaf5feef3c",
     "grade": false,
     "grade_id": "cell-4374dd3b71e3e1aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.linalg import VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F \n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "527fbbddcd0832714c2618aa70ee0cbd",
     "grade": false,
     "grade_id": "cell-d28fe8378ff439c1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Data preparation\n",
    "\n",
    "Even though MLlib is designed with RDDs and DStreams in focus, for ease of transforming the data we will read the data and convert it to a DataFrame. Afterwards we will build RDDs for training in MLlib, or stay in DataFrame for training in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'titanic.csv'\n",
    "data = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load(filePath)\n",
    "#data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f6b121e284c520dc982f47aa2a64dab",
     "grade": false,
     "grade_id": "cell-ca71837cedb092f5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.3838383838383838</td>\n",
       "      <td>2.308641975308642</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>29.69911764705882</td>\n",
       "      <td>0.5230078563411896</td>\n",
       "      <td>0.38159371492704824</td>\n",
       "      <td>260318.54916792738</td>\n",
       "      <td>32.2042079685746</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>257.3538420152301</td>\n",
       "      <td>0.48659245426485753</td>\n",
       "      <td>0.8360712409770491</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14.526497332334035</td>\n",
       "      <td>1.1027434322934315</td>\n",
       "      <td>0.8060572211299488</td>\n",
       "      <td>471609.26868834975</td>\n",
       "      <td>49.69342859718089</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"</td>\n",
       "      <td>female</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>891</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>WE/P 5735</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>T</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary        PassengerId             Survived              Pclass  \\\n",
       "0   count                891                  891                 891   \n",
       "1    mean              446.0   0.3838383838383838   2.308641975308642   \n",
       "2  stddev  257.3538420152301  0.48659245426485753  0.8360712409770491   \n",
       "3     min                  1                    0                   1   \n",
       "4     max                891                    1                   3   \n",
       "\n",
       "                                               Name     Sex  \\\n",
       "0                                               891     891   \n",
       "1                                              None    None   \n",
       "2                                              None    None   \n",
       "3  \"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"  female   \n",
       "4                       van Melkebeke, Mr. Philemon    male   \n",
       "\n",
       "                  Age               SibSp                Parch  \\\n",
       "0                 714                 891                  891   \n",
       "1   29.69911764705882  0.5230078563411896  0.38159371492704824   \n",
       "2  14.526497332334035  1.1027434322934315   0.8060572211299488   \n",
       "3                0.42                   0                    0   \n",
       "4                80.0                   8                    6   \n",
       "\n",
       "               Ticket               Fare Cabin Embarked  \n",
       "0                 891                891   204      889  \n",
       "1  260318.54916792738   32.2042079685746  None     None  \n",
       "2  471609.26868834975  49.69342859718089  None     None  \n",
       "3              110152                0.0   A10        C  \n",
       "4           WE/P 5735           512.3292     T        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27af6323e3cbecc226fa71cdd931a8ea",
     "grade": false,
     "grade_id": "cell-1ffea3dfd43c7ce6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "From the first summary statistics, we see that the `Age`, `Cabin` and `Embarked` variables can have null values. Also `PassengerId` and `Ticket` look useless for future predictions.\n",
    "\n",
    "# Question\n",
    "  \n",
    "* Drop `Cabin`, `Ticket` and `PassengerId`\n",
    "* Using `.na.fill` function on a DataFrame :\n",
    "    * For `Age`, replace `None` by the mean value for the column. \n",
    "    * For `Embarked` columns, replace `None` by the most frequent value for the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8981ccf6f3077abd1ad00725d9eb21db",
     "grade": false,
     "grade_id": "cell-852a22563e2c66a2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_na(df):\n",
    "    \"\"\"\n",
    "    Deal with na values, and drop selected columns    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    columns_to_drop = [\"Cabin\",\"Ticket\",\"PassengerId\"]\n",
    "    df = df.drop(*columns_to_drop)\n",
    "\n",
    "    df.show()\n",
    "    mean_val = df.select(mean(df.Age)).collect()\n",
    "    print(type(mean_val)) #mean_val is a list row object\n",
    "    print('mean value of Age', mean_val[0][0])\n",
    "    mean_age = mean_val[0][0]\n",
    "    #now using mean_age value to fill the nulls in sales column\n",
    "    df = df.na.fill(mean_age,subset=['Age'])\n",
    "    df.show()\n",
    "\n",
    "    \n",
    "    counts = df.groupBy(\"Embarked\").count().collect()\n",
    "    print(\"Embarked counts before Na removal ->\",counts)\n",
    "    \n",
    "    value, max_count = None, 0\n",
    "    for count in counts:\n",
    "        if count[1]>max_count:\n",
    "            value = count[0]\n",
    "            max_count = count[1]\n",
    "    print(\"value, max_count ->\",value, max_count)\n",
    "    \n",
    "    df = df.na.fill(value,subset=['Embarked'])\n",
    "    \n",
    "    counts2 = df.groupBy(\"Embarked\").count().collect()\n",
    "    print(\"Embarked counts after Na removal ->\",counts2)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "495eb4f93d97689053c64d07cc38cc68",
     "grade": true,
     "grade_id": "cell-9c65ef235a646501",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|null|    0|    0| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|30.0708|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|   16.7|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  26.55|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5| 31.275|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0| 7.8542|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|   16.0|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1| 29.125|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|   13.0|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|  7.225|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "<class 'list'>\n",
      "mean value of Age 29.69911764705882\n",
      "+--------+------+--------------------+------+-----------------+-----+-----+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex|              Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+-----------------+-----+-----+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|30.0708|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female|              4.0|    1|    1|   16.7|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|             58.0|    0|    0|  26.55|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|             20.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|             39.0|    1|    5| 31.275|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|             14.0|    0|    0| 7.8542|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|             55.0|    0|    0|   16.0|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male|              2.0|    4|    1| 29.125|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male|29.69911764705882|    0|    0|   13.0|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|             31.0|    1|    0|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|29.69911764705882|    0|    0|  7.225|       C|\n",
      "+--------+------+--------------------+------+-----------------+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Embarked counts before Na removal -> [Row(Embarked='Q', count=77), Row(Embarked=None, count=2), Row(Embarked='C', count=168), Row(Embarked='S', count=644)]\n",
      "value, max_count -> S 644\n",
      "Embarked counts after Na removal -> [Row(Embarked='Q', count=77), Row(Embarked='C', count=168), Row(Embarked='S', count=646)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "result = replace_na(data)\n",
    "assert float(result.describe().toPandas().loc[2]['Age']) - 13 < 0.1\n",
    "assert int(result.describe().toPandas().loc[0]['Embarked']) == 891\n",
    "assert list(result.toPandas().columns.values) == ['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1de211c78b3973a7f5d921c6b072d06a",
     "grade": false,
     "grade_id": "cell-c720dda0d25f41c5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For the following two questions, we will use [Transformers](https://spark.apache.org/docs/2.2.0/ml-pipeline.html#transformers). Technically, a Transformer implements a method `transform()`, which converts one DataFrame into another, generally by appending one or more columns.\n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "continuousDataFrame = spark.createDataFrame([\n",
    "    (0, 0.1),\n",
    "    (1, 0.8),\n",
    "    (2, 0.2)\n",
    "], [\"id\", \"feature\"])\n",
    "continuousDataFrame.show()\n",
    "\n",
    "binarizer = Binarizer(threshold=0.5, inputCol=\"feature\", outputCol=\"binarized_feature\")\n",
    "binarizedDataFrame = binarizer.transform(continuousDataFrame)\n",
    "print(\"Binarizer output with Threshold = %f\" % binarizer.getThreshold())\n",
    "binarizedDataFrame.show()\n",
    "```\n",
    "\n",
    "Result :\n",
    "\n",
    "```\n",
    "+---+-------+\n",
    "| id|feature|\n",
    "+---+-------+\n",
    "|  0|    0.1|\n",
    "|  1|    0.8|\n",
    "|  2|    0.2|\n",
    "+---+-------+\n",
    "\n",
    "Binarizer output with Threshold = 0.500000\n",
    "+---+-------+-----------------+\n",
    "| id|feature|binarized_feature|\n",
    "+---+-------+-----------------+\n",
    "|  0|    0.1|              0.0|\n",
    "|  1|    0.8|              1.0|\n",
    "|  2|    0.2|              0.0|\n",
    "+---+-------+-----------------+\n",
    "```\n",
    "\n",
    "**Note:** contrary to previous notebooks, I have not imported all of the libraries needed to solve the remaining exercises. When you want to import a library, please import it in the same notebook cell as where you implement your code, otherwise it may impact the automatic grading.\n",
    "\n",
    "# Question\n",
    "\n",
    "Through some regex, the [regex_extract UDF](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF) and [SQLTransformer](https://spark.apache.org/docs/2.2.0/ml-features.html#sqltransformer), get the title of a person from the `Name` column in a `Title` column. Drop the `Name` column afterwards.\n",
    "\n",
    "Example\n",
    "\n",
    "```\n",
    "Braund, Mr. Owen       --> Mr\n",
    "Andria, Doctor. Steve  --> Doctor\n",
    "```\n",
    "\n",
    "_Not a hint: while it is perfectly possible to write a custom UDF to solve this question, it breaks the purpose of using Dataframes for cleaning because UDFs don't benefit from SparkSQL's optimizer engine and have to transform back to Java objects for processing. Spark built-in UDFs don't share this problem._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>\"Johnston, Miss. Catherine Helen \"\"Carrie\"\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888       \"Johnston, Miss. Catherine Helen \"\"Carrie\"\"\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500  None        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250  None        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500  None        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000  None        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500  None        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500  None        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reserve = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_reserve.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regulaar Expressions Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example1\n",
    "# text = [\"March 8,2019\", \"march 8, 2019\", \"march 8 2019\", \n",
    "#         \"mar 30 2019\", \"Countermarch 8,2019 feet\", \"marched\"]\n",
    "\n",
    "# df = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
    "\n",
    "# df = df.withColumn(\"date_from_text\", F.regexp_extract(df.text, r\"(\\b(?:[M|m]ar(?:ch)?)\\b [0-9]+,?(?: |)\\d{4})\", 0))          \n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example2\n",
    "# names = [\"Braund, Mr. Owen\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Heikkinen, Miss. Laina\", \n",
    "#         \"Behr, Mr. Karl Howell\", \"Graham, Miss. Margaret Edith\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\"]\n",
    "# df = spark.createDataFrame(names, StringType()).toDF(\"names\")\n",
    "\n",
    "# df = df.withColumn(\"title_from_name\", F.regexp_extract(df.names, '\\w+\\.', 0))          \n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rex = re.compile('\\w+\\.')\n",
    "# names = [\"Braund, Mr. Owen\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Heikkinen, Miss. Laina\", \n",
    "#         \"Behr, Mr. Karl Howell\", \"Graham, Miss. Margaret Edith\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\"]\n",
    "# result = []\n",
    "# for name in names:\n",
    "#     result.append(rex.findall(name))\n",
    "    \n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example4\n",
    "# adresses = [\"Ema Dough (+1-202-555-0189) - 915 Ridge Street Corpus, TX 78418\",\n",
    "#  \"Tom Hitt (+33-93-751-3845) - 9190 Berkshire Ave. Wayne, NJ 07470\",\n",
    "#  \"Maya Raine (+49-30-833-931-313) - 18 SW. Sage Ave. Ride, CA 95993\"]\n",
    "\n",
    "# phone_numbers = [] \n",
    "# pattern = r\"\\(([\\d\\-+]+)\\)\"\n",
    "\n",
    "# for adress in adresses: \n",
    "#     result = re.search(pattern, adress)\n",
    "#     phone_numbers.append(result.group(1))\n",
    "# print(phone_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f63d00d042b0e75410b2cb613b62c616",
     "grade": false,
     "grade_id": "cell-93a47dbea9af3ed9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_civility(df):\n",
    "    \"\"\"\n",
    "    Return dataframe dropping Name and replacing with Civility\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    data = df.withColumn(\"Civility\", F.regexp_extract(df.Name, '\\w+\\.', 0)) \n",
    "    columns_to_drop = [\"Name\"]\n",
    "    data = data.drop(*columns_to_drop)\n",
    "    #data.show()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Civility|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|          1|       0|     3|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr.|\n",
      "|          2|       1|     1|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs.|\n",
      "|          3|       1|     3|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss.|\n",
      "|          4|       1|     1|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs.|\n",
      "|          5|       0|     3|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr.|\n",
      "|          6|       0|     3|  male|null|    0|    0|          330877| 8.4583| null|       Q|     Mr.|\n",
      "|          7|       0|     1|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr.|\n",
      "|          8|       0|     3|  male| 2.0|    3|    1|          349909| 21.075| null|       S| Master.|\n",
      "|          9|       1|     3|female|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs.|\n",
      "|         10|       1|     2|female|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs.|\n",
      "|         11|       1|     3|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss.|\n",
      "|         12|       1|     1|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss.|\n",
      "|         13|       0|     3|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr.|\n",
      "|         14|       0|     3|  male|39.0|    1|    5|          347082| 31.275| null|       S|     Mr.|\n",
      "|         15|       0|     3|female|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss.|\n",
      "|         16|       1|     2|female|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs.|\n",
      "|         17|       0|     3|  male| 2.0|    4|    1|          382652| 29.125| null|       Q| Master.|\n",
      "|         18|       1|     2|  male|null|    0|    0|          244373|   13.0| null|       S|     Mr.|\n",
      "|         19|       0|     3|female|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs.|\n",
      "|         20|       1|     3|female|null|    0|    0|            2649|  7.225| null|       C|    Mrs.|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "result = extract_civility(data)\n",
    "resultCols = result.columns\n",
    "assert 'Name' not in resultCols\n",
    "assert 'Civility' in resultCols\n",
    "assert list(result.select('Civility').distinct().toPandas()['Civility'].sort_values().values) == ['Capt.',\n",
    " 'Col.',\n",
    " 'Countess.',\n",
    " 'Don.',\n",
    " 'Dr.',\n",
    " 'Jonkheer.',\n",
    " 'Lady.',\n",
    " 'Major.',\n",
    " 'Master.',\n",
    " 'Miss.',\n",
    " 'Mlle.',\n",
    " 'Mme.',\n",
    " 'Mr.',\n",
    " 'Mrs.',\n",
    " 'Ms.',\n",
    " 'Rev.',\n",
    " 'Sir.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaf4120d9637141e40ac9327d2061d52",
     "grade": true,
     "grade_id": "cell-c98d26534a8b160c",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "result = extract_civility(data)\n",
    "resultCols = result.columns\n",
    "assert 'Name' not in resultCols\n",
    "assert 'Civility' in resultCols\n",
    "assert list(result.select('Civility').distinct().toPandas()['Civility'].sort_values().values) == [\n",
    "    'Capt',\n",
    "    'Col',\n",
    "    'Don',\n",
    "    'Dr',\n",
    "    'Jonkheer',\n",
    "    'Lady',\n",
    "    'Major',\n",
    "    'Master',\n",
    "    'Miss',\n",
    "    'Mlle',\n",
    "    'Mme',\n",
    "    'Mr',\n",
    "    'Mrs',\n",
    "    'Ms',\n",
    "    'Rev',\n",
    "    'Sir',\n",
    "    'the Countess'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "840b8c2bfea63a5ef297d22ad9a756a8",
     "grade": false,
     "grade_id": "cell-263e03090b6d1030",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Question \n",
    "\n",
    "[One hot encode](https://spark.apache.org/docs/2.2.0/ml-features.html#onehotencoder) `Sex`, `Civility` and `Embarked` columns into `SexVec`, `CivilityVec` and `EmbarkedVec`. Don't forget to drop the original columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SQLContext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6b4d618fd002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msqlContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m df = sqlContext.createDataFrame([\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SQLContext' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "df = sqlContext.createDataFrame([\n",
    "    (0, \"a\"),\n",
    "    (1, \"b\"),\n",
    "    (2, \"c\"),\n",
    "    (3, \"a\"),\n",
    "    (4, \"a\"),\n",
    "    (5, \"c\")\n",
    "], [\"id\", \"category\"])\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indexed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6a65fea63557>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropLast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categoryIndex\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categoryVec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"categoryVec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'indexed' is not defined"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"categoryIndex\", outputCol=\"categoryVec\")\n",
    "ohe = encoder.fit(indexed)\n",
    "encoded = ohe.transform(indexed)\n",
    "encoded.select(\"id\", \"categoryVec\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "##### Onehot encode Sex, Civility and Embarked columns into SexVec, CivilityVec and EmbarkedVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Civility|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "|          1|       0|     3|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr.|\n",
      "|          2|       1|     1|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs.|\n",
      "|          3|       1|     3|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss.|\n",
      "|          4|       1|     1|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs.|\n",
      "|          5|       0|     3|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr.|\n",
      "|          6|       0|     3|  male|null|    0|    0|          330877| 8.4583| null|       Q|     Mr.|\n",
      "|          7|       0|     1|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr.|\n",
      "|          8|       0|     3|  male| 2.0|    3|    1|          349909| 21.075| null|       S| Master.|\n",
      "|          9|       1|     3|female|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs.|\n",
      "|         10|       1|     2|female|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs.|\n",
      "|         11|       1|     3|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss.|\n",
      "|         12|       1|     1|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss.|\n",
      "|         13|       0|     3|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr.|\n",
      "|         14|       0|     3|  male|39.0|    1|    5|          347082| 31.275| null|       S|     Mr.|\n",
      "|         15|       0|     3|female|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss.|\n",
      "|         16|       1|     2|female|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs.|\n",
      "|         17|       0|     3|  male| 2.0|    4|    1|          382652| 29.125| null|       Q| Master.|\n",
      "|         18|       1|     2|  male|null|    0|    0|          244373|   13.0| null|       S|     Mr.|\n",
      "|         19|       0|     3|female|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs.|\n",
      "|         20|       1|     3|female|null|    0|    0|            2649|  7.225| null|       C|    Mrs.|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()\n",
    "df=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+--------+\n",
      "|PassengerId|Survived|Pclass|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Civility|SexIndex|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+--------+\n",
      "|          1|       0|     3|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr.|     0.0|\n",
      "|          2|       1|     1|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs.|     1.0|\n",
      "|          3|       1|     3|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss.|     1.0|\n",
      "|          4|       1|     1|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs.|     1.0|\n",
      "|          5|       0|     3|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr.|     0.0|\n",
      "|          6|       0|     3|  male|null|    0|    0|          330877| 8.4583| null|       Q|     Mr.|     0.0|\n",
      "|          7|       0|     1|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr.|     0.0|\n",
      "|          8|       0|     3|  male| 2.0|    3|    1|          349909| 21.075| null|       S| Master.|     0.0|\n",
      "|          9|       1|     3|female|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs.|     1.0|\n",
      "|         10|       1|     2|female|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs.|     1.0|\n",
      "|         11|       1|     3|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss.|     1.0|\n",
      "|         12|       1|     1|female|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss.|     1.0|\n",
      "|         13|       0|     3|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr.|     0.0|\n",
      "|         14|       0|     3|  male|39.0|    1|    5|          347082| 31.275| null|       S|     Mr.|     0.0|\n",
      "|         15|       0|     3|female|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss.|     1.0|\n",
      "|         16|       1|     2|female|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs.|     1.0|\n",
      "|         17|       0|     3|  male| 2.0|    4|    1|          382652| 29.125| null|       Q| Master.|     0.0|\n",
      "|         18|       1|     2|  male|null|    0|    0|          244373|   13.0| null|       S|     Mr.|     0.0|\n",
      "|         19|       0|     3|female|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs.|     1.0|\n",
      "|         20|       1|     3|female|null|    0|    0|            2649|  7.225| null|       C|    Mrs.|     1.0|\n",
      "+-----------+--------+------+------+----+-----+-----+----------------+-------+-----+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+--------+-------------+\n",
      "|PassengerId|Survived|Pclass| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Civility|       SexVec|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+--------+-------------+\n",
      "|          1|       0|     3|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr.|(1,[0],[1.0])|\n",
      "|          2|       1|     1|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs.|    (1,[],[])|\n",
      "|          3|       1|     3|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss.|    (1,[],[])|\n",
      "|          4|       1|     1|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs.|    (1,[],[])|\n",
      "|          5|       0|     3|35.0|    0|    0|          373450|   8.05| null|       S|     Mr.|(1,[0],[1.0])|\n",
      "|          6|       0|     3|null|    0|    0|          330877| 8.4583| null|       Q|     Mr.|(1,[0],[1.0])|\n",
      "|          7|       0|     1|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr.|(1,[0],[1.0])|\n",
      "|          8|       0|     3| 2.0|    3|    1|          349909| 21.075| null|       S| Master.|(1,[0],[1.0])|\n",
      "|          9|       1|     3|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs.|    (1,[],[])|\n",
      "|         10|       1|     2|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs.|    (1,[],[])|\n",
      "|         11|       1|     3| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss.|    (1,[],[])|\n",
      "|         12|       1|     1|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss.|    (1,[],[])|\n",
      "|         13|       0|     3|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr.|(1,[0],[1.0])|\n",
      "|         14|       0|     3|39.0|    1|    5|          347082| 31.275| null|       S|     Mr.|(1,[0],[1.0])|\n",
      "|         15|       0|     3|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss.|    (1,[],[])|\n",
      "|         16|       1|     2|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs.|    (1,[],[])|\n",
      "|         17|       0|     3| 2.0|    4|    1|          382652| 29.125| null|       Q| Master.|(1,[0],[1.0])|\n",
      "|         18|       1|     2|null|    0|    0|          244373|   13.0| null|       S|     Mr.|(1,[0],[1.0])|\n",
      "|         19|       0|     3|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs.|    (1,[],[])|\n",
      "|         20|       1|     3|null|    0|    0|            2649|  7.225| null|       C|    Mrs.|    (1,[],[])|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sex\n",
    "stringIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "indexed.show()\n",
    "\n",
    "encoder = OneHotEncoder(dropLast=True, inputCol=\"SexIndex\", outputCol=\"SexVec\")\n",
    "ohe = encoder.fit(indexed)\n",
    "encoded = ohe.transform(indexed)\n",
    "encoded = encoded.drop(\"SexIndex\",\"Sex\")\n",
    "encoded.show()\n",
    "df=encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+--------+-------------+-------------+\n",
      "|PassengerId|Survived|Pclass| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Civility|       SexVec|CivilityIndex|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+--------+-------------+-------------+\n",
      "|          1|       0|     3|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr.|(1,[0],[1.0])|          0.0|\n",
      "|          2|       1|     1|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs.|    (1,[],[])|          2.0|\n",
      "|          3|       1|     3|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss.|    (1,[],[])|          1.0|\n",
      "|          4|       1|     1|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs.|    (1,[],[])|          2.0|\n",
      "|          5|       0|     3|35.0|    0|    0|          373450|   8.05| null|       S|     Mr.|(1,[0],[1.0])|          0.0|\n",
      "|          6|       0|     3|null|    0|    0|          330877| 8.4583| null|       Q|     Mr.|(1,[0],[1.0])|          0.0|\n",
      "|          7|       0|     1|54.0|    0|    0|           17463|51.8625|  E46|       S|     Mr.|(1,[0],[1.0])|          0.0|\n",
      "|          8|       0|     3| 2.0|    3|    1|          349909| 21.075| null|       S| Master.|(1,[0],[1.0])|          3.0|\n",
      "|          9|       1|     3|27.0|    0|    2|          347742|11.1333| null|       S|    Mrs.|    (1,[],[])|          2.0|\n",
      "|         10|       1|     2|14.0|    1|    0|          237736|30.0708| null|       C|    Mrs.|    (1,[],[])|          2.0|\n",
      "|         11|       1|     3| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|   Miss.|    (1,[],[])|          1.0|\n",
      "|         12|       1|     1|58.0|    0|    0|          113783|  26.55| C103|       S|   Miss.|    (1,[],[])|          1.0|\n",
      "|         13|       0|     3|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|     Mr.|(1,[0],[1.0])|          0.0|\n",
      "|         14|       0|     3|39.0|    1|    5|          347082| 31.275| null|       S|     Mr.|(1,[0],[1.0])|          0.0|\n",
      "|         15|       0|     3|14.0|    0|    0|          350406| 7.8542| null|       S|   Miss.|    (1,[],[])|          1.0|\n",
      "|         16|       1|     2|55.0|    0|    0|          248706|   16.0| null|       S|    Mrs.|    (1,[],[])|          2.0|\n",
      "|         17|       0|     3| 2.0|    4|    1|          382652| 29.125| null|       Q| Master.|(1,[0],[1.0])|          3.0|\n",
      "|         18|       1|     2|null|    0|    0|          244373|   13.0| null|       S|     Mr.|(1,[0],[1.0])|          0.0|\n",
      "|         19|       0|     3|31.0|    1|    0|          345763|   18.0| null|       S|    Mrs.|    (1,[],[])|          2.0|\n",
      "|         20|       1|     3|null|    0|    0|            2649|  7.225| null|       C|    Mrs.|    (1,[],[])|          2.0|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+--------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+-------------+--------------+\n",
      "|PassengerId|Survived|Pclass| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|       SexVec|   CivilityVec|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+-------------+--------------+\n",
      "|          1|       0|     3|22.0|    1|    0|       A/5 21171|   7.25| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|\n",
      "|          2|       1|     1|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    (1,[],[])|(17,[2],[1.0])|\n",
      "|          3|       1|     3|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|    (1,[],[])|(17,[1],[1.0])|\n",
      "|          4|       1|     1|35.0|    1|    0|          113803|   53.1| C123|       S|    (1,[],[])|(17,[2],[1.0])|\n",
      "|          5|       0|     3|35.0|    0|    0|          373450|   8.05| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|\n",
      "|          6|       0|     3|null|    0|    0|          330877| 8.4583| null|       Q|(1,[0],[1.0])|(17,[0],[1.0])|\n",
      "|          7|       0|     1|54.0|    0|    0|           17463|51.8625|  E46|       S|(1,[0],[1.0])|(17,[0],[1.0])|\n",
      "|          8|       0|     3| 2.0|    3|    1|          349909| 21.075| null|       S|(1,[0],[1.0])|(17,[3],[1.0])|\n",
      "|          9|       1|     3|27.0|    0|    2|          347742|11.1333| null|       S|    (1,[],[])|(17,[2],[1.0])|\n",
      "|         10|       1|     2|14.0|    1|    0|          237736|30.0708| null|       C|    (1,[],[])|(17,[2],[1.0])|\n",
      "|         11|       1|     3| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|    (1,[],[])|(17,[1],[1.0])|\n",
      "|         12|       1|     1|58.0|    0|    0|          113783|  26.55| C103|       S|    (1,[],[])|(17,[1],[1.0])|\n",
      "|         13|       0|     3|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|\n",
      "|         14|       0|     3|39.0|    1|    5|          347082| 31.275| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|\n",
      "|         15|       0|     3|14.0|    0|    0|          350406| 7.8542| null|       S|    (1,[],[])|(17,[1],[1.0])|\n",
      "|         16|       1|     2|55.0|    0|    0|          248706|   16.0| null|       S|    (1,[],[])|(17,[2],[1.0])|\n",
      "|         17|       0|     3| 2.0|    4|    1|          382652| 29.125| null|       Q|(1,[0],[1.0])|(17,[3],[1.0])|\n",
      "|         18|       1|     2|null|    0|    0|          244373|   13.0| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|\n",
      "|         19|       0|     3|31.0|    1|    0|          345763|   18.0| null|       S|    (1,[],[])|(17,[2],[1.0])|\n",
      "|         20|       1|     3|null|    0|    0|            2649|  7.225| null|       C|    (1,[],[])|(17,[2],[1.0])|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Civility\n",
    "stringIndexer = StringIndexer(inputCol=\"Civility\", outputCol=\"CivilityIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "indexed.show()\n",
    "\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"CivilityIndex\", outputCol=\"CivilityVec\")\n",
    "ohe = encoder.fit(indexed)\n",
    "encoded = ohe.transform(indexed)\n",
    "encoded = encoded.drop(\"CivilityIndex\", \"Civility\")\n",
    "encoded.show()\n",
    "df=encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+-------------+--------------+-------------+\n",
      "|PassengerId|Survived|Pclass| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|       SexVec|   CivilityVec|EmbarkedIndex|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+-------------+--------------+-------------+\n",
      "|          1|       0|     3|22.0|    1|    0|       A/5 21171|   7.25| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|          0.0|\n",
      "|          2|       1|     1|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    (1,[],[])|(17,[2],[1.0])|          1.0|\n",
      "|          3|       1|     3|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|    (1,[],[])|(17,[1],[1.0])|          0.0|\n",
      "|          4|       1|     1|35.0|    1|    0|          113803|   53.1| C123|       S|    (1,[],[])|(17,[2],[1.0])|          0.0|\n",
      "|          5|       0|     3|35.0|    0|    0|          373450|   8.05| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|          0.0|\n",
      "|          6|       0|     3|null|    0|    0|          330877| 8.4583| null|       Q|(1,[0],[1.0])|(17,[0],[1.0])|          2.0|\n",
      "|          7|       0|     1|54.0|    0|    0|           17463|51.8625|  E46|       S|(1,[0],[1.0])|(17,[0],[1.0])|          0.0|\n",
      "|          8|       0|     3| 2.0|    3|    1|          349909| 21.075| null|       S|(1,[0],[1.0])|(17,[3],[1.0])|          0.0|\n",
      "|          9|       1|     3|27.0|    0|    2|          347742|11.1333| null|       S|    (1,[],[])|(17,[2],[1.0])|          0.0|\n",
      "|         10|       1|     2|14.0|    1|    0|          237736|30.0708| null|       C|    (1,[],[])|(17,[2],[1.0])|          1.0|\n",
      "|         11|       1|     3| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|    (1,[],[])|(17,[1],[1.0])|          0.0|\n",
      "|         12|       1|     1|58.0|    0|    0|          113783|  26.55| C103|       S|    (1,[],[])|(17,[1],[1.0])|          0.0|\n",
      "|         13|       0|     3|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|          0.0|\n",
      "|         14|       0|     3|39.0|    1|    5|          347082| 31.275| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|          0.0|\n",
      "|         15|       0|     3|14.0|    0|    0|          350406| 7.8542| null|       S|    (1,[],[])|(17,[1],[1.0])|          0.0|\n",
      "|         16|       1|     2|55.0|    0|    0|          248706|   16.0| null|       S|    (1,[],[])|(17,[2],[1.0])|          0.0|\n",
      "|         17|       0|     3| 2.0|    4|    1|          382652| 29.125| null|       Q|(1,[0],[1.0])|(17,[3],[1.0])|          2.0|\n",
      "|         18|       1|     2|null|    0|    0|          244373|   13.0| null|       S|(1,[0],[1.0])|(17,[0],[1.0])|          0.0|\n",
      "|         19|       0|     3|31.0|    1|    0|          345763|   18.0| null|       S|    (1,[],[])|(17,[2],[1.0])|          0.0|\n",
      "|         20|       1|     3|null|    0|    0|            2649|  7.225| null|       C|    (1,[],[])|(17,[2],[1.0])|          1.0|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+--------+-------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+-------------+--------------+-------------+\n",
      "|PassengerId|Survived|Pclass| Age|SibSp|Parch|          Ticket|   Fare|Cabin|       SexVec|   CivilityVec|  EmbarkedVec|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+-------------+--------------+-------------+\n",
      "|          1|       0|     3|22.0|    1|    0|       A/5 21171|   7.25| null|(1,[0],[1.0])|(17,[0],[1.0])|(3,[0],[1.0])|\n",
      "|          2|       1|     1|38.0|    1|    0|        PC 17599|71.2833|  C85|    (1,[],[])|(17,[2],[1.0])|(3,[1],[1.0])|\n",
      "|          3|       1|     3|26.0|    0|    0|STON/O2. 3101282|  7.925| null|    (1,[],[])|(17,[1],[1.0])|(3,[0],[1.0])|\n",
      "|          4|       1|     1|35.0|    1|    0|          113803|   53.1| C123|    (1,[],[])|(17,[2],[1.0])|(3,[0],[1.0])|\n",
      "|          5|       0|     3|35.0|    0|    0|          373450|   8.05| null|(1,[0],[1.0])|(17,[0],[1.0])|(3,[0],[1.0])|\n",
      "|          6|       0|     3|null|    0|    0|          330877| 8.4583| null|(1,[0],[1.0])|(17,[0],[1.0])|(3,[2],[1.0])|\n",
      "|          7|       0|     1|54.0|    0|    0|           17463|51.8625|  E46|(1,[0],[1.0])|(17,[0],[1.0])|(3,[0],[1.0])|\n",
      "|          8|       0|     3| 2.0|    3|    1|          349909| 21.075| null|(1,[0],[1.0])|(17,[3],[1.0])|(3,[0],[1.0])|\n",
      "|          9|       1|     3|27.0|    0|    2|          347742|11.1333| null|    (1,[],[])|(17,[2],[1.0])|(3,[0],[1.0])|\n",
      "|         10|       1|     2|14.0|    1|    0|          237736|30.0708| null|    (1,[],[])|(17,[2],[1.0])|(3,[1],[1.0])|\n",
      "|         11|       1|     3| 4.0|    1|    1|         PP 9549|   16.7|   G6|    (1,[],[])|(17,[1],[1.0])|(3,[0],[1.0])|\n",
      "|         12|       1|     1|58.0|    0|    0|          113783|  26.55| C103|    (1,[],[])|(17,[1],[1.0])|(3,[0],[1.0])|\n",
      "|         13|       0|     3|20.0|    0|    0|       A/5. 2151|   8.05| null|(1,[0],[1.0])|(17,[0],[1.0])|(3,[0],[1.0])|\n",
      "|         14|       0|     3|39.0|    1|    5|          347082| 31.275| null|(1,[0],[1.0])|(17,[0],[1.0])|(3,[0],[1.0])|\n",
      "|         15|       0|     3|14.0|    0|    0|          350406| 7.8542| null|    (1,[],[])|(17,[1],[1.0])|(3,[0],[1.0])|\n",
      "|         16|       1|     2|55.0|    0|    0|          248706|   16.0| null|    (1,[],[])|(17,[2],[1.0])|(3,[0],[1.0])|\n",
      "|         17|       0|     3| 2.0|    4|    1|          382652| 29.125| null|(1,[0],[1.0])|(17,[3],[1.0])|(3,[2],[1.0])|\n",
      "|         18|       1|     2|null|    0|    0|          244373|   13.0| null|(1,[0],[1.0])|(17,[0],[1.0])|(3,[0],[1.0])|\n",
      "|         19|       0|     3|31.0|    1|    0|          345763|   18.0| null|    (1,[],[])|(17,[2],[1.0])|(3,[0],[1.0])|\n",
      "|         20|       1|     3|null|    0|    0|            2649|  7.225| null|    (1,[],[])|(17,[2],[1.0])|(3,[1],[1.0])|\n",
      "+-----------+--------+------+----+-----+-----+----------------+-------+-----+-------------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Embarked\n",
    "stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
    "model = stringIndexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "indexed.show()\n",
    "\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"EmbarkedIndex\", outputCol=\"EmbarkedVec\")\n",
    "ohe = encoder.fit(indexed)\n",
    "encoded = ohe.transform(indexed)\n",
    "encoded = encoded.drop(\"EmbarkedIndex\", \"Embarked\")\n",
    "encoded.show()\n",
    "#encoded.select(\"Survived\",\"Age\" ,\"EmbarkedVec\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------------+-------------+--------------+\n",
      "|Survived| Age|       SexVec|  EmbarkedVec|   CivilityVec|\n",
      "+--------+----+-------------+-------------+--------------+\n",
      "|       0|22.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       1|38.0|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "|       1|26.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|35.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       0|35.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|null|(1,[0],[1.0])|(3,[2],[1.0])|(17,[0],[1.0])|\n",
      "|       0|54.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0| 2.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[3],[1.0])|\n",
      "|       1|27.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       1|14.0|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "|       1| 4.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|58.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       0|20.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|39.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|14.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|55.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       0| 2.0|(1,[0],[1.0])|(3,[2],[1.0])|(17,[3],[1.0])|\n",
      "|       1|null|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|31.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       1|null|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "+--------+----+-------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded.select(\"Survived\",\"Age\" ,\"SexVec\",\"EmbarkedVec\",\"CivilityVec\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6fc89f3c0a93f77ce190d1f08ccd505",
     "grade": false,
     "grade_id": "cell-87b6e00fa578a061",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    \"\"\"\n",
    "    Return dataframe one hot encoding selected columns    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Sex\n",
    "    stringIndexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
    "    model = stringIndexer.fit(df)\n",
    "    indexed = model.transform(df)\n",
    "    encoder = OneHotEncoder(dropLast=True, inputCol=\"SexIndex\", outputCol=\"SexVec\")\n",
    "    ohe = encoder.fit(indexed)\n",
    "    df = ohe.transform(indexed)\n",
    "    \n",
    "    # Civility\n",
    "    stringIndexer = StringIndexer(inputCol=\"Civility\", outputCol=\"CivilityIndex\")\n",
    "    model = stringIndexer.fit(df)\n",
    "    indexed = model.transform(df)\n",
    "    encoder = OneHotEncoder(dropLast=False, inputCol=\"CivilityIndex\", outputCol=\"CivilityVec\")\n",
    "    ohe = encoder.fit(indexed)\n",
    "    df = ohe.transform(indexed)\n",
    "    \n",
    "    # Embarked\n",
    "    stringIndexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n",
    "    model = stringIndexer.fit(df)\n",
    "    indexed = model.transform(df)\n",
    "    encoder = OneHotEncoder(dropLast=False, inputCol=\"EmbarkedIndex\", outputCol=\"EmbarkedVec\")\n",
    "    ohe = encoder.fit(indexed)\n",
    "    df = ohe.transform(indexed)\n",
    "    \n",
    "    df = df.drop(\"EmbarkedIndex\", \"Embarked\",\"CivilityIndex\", \"Civility\",\"SexIndex\",\"Sex\")\n",
    "    df.select(\"Survived\",\"Age\" ,\"SexVec\",\"EmbarkedVec\",\"CivilityVec\").show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1700e84915682868d08698e63761e2e",
     "grade": true,
     "grade_id": "cell-2ca43cb570eae17b",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-------------+-------------+--------------+\n",
      "|Survived| Age|       SexVec|  EmbarkedVec|   CivilityVec|\n",
      "+--------+----+-------------+-------------+--------------+\n",
      "|       0|22.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       1|38.0|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "|       1|26.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|35.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       0|35.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|null|(1,[0],[1.0])|(3,[2],[1.0])|(17,[0],[1.0])|\n",
      "|       0|54.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0| 2.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[3],[1.0])|\n",
      "|       1|27.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       1|14.0|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "|       1| 4.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|58.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       0|20.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|39.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|14.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|55.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       0| 2.0|(1,[0],[1.0])|(3,[2],[1.0])|(17,[3],[1.0])|\n",
      "|       1|null|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|31.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       1|null|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "+--------+----+-------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "result = one_hot_encode(extract_civility(data))\n",
    "resultCols = result.columns\n",
    "assert len(resultCols) == 12\n",
    "\n",
    "assert 'SexVec' in resultCols\n",
    "assert 'CivilityVec' in resultCols\n",
    "assert 'EmbarkedVec' in resultCols\n",
    "\n",
    "assert 'Sex' not in resultCols\n",
    "assert 'Civility' not in resultCols\n",
    "assert 'Embarked' not in resultCols\n",
    "\n",
    "assert result.schema['SexVec'].simpleString() == 'SexVec:vector'\n",
    "assert result.schema['CivilityVec'].simpleString() == 'CivilityVec:vector'\n",
    "assert result.schema['EmbarkedVec'].simpleString() == 'EmbarkedVec:vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dab91b6c7834a91ffce574703c292c6a",
     "grade": false,
     "grade_id": "cell-eea586c0506e7fed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Question\n",
    "\n",
    "Now that we have created all of our numeric features, we need to assemble them into the same column. This is the goal of the [VectorAssembler](https://spark.apache.org/docs/2.2.0/ml-features.html#vectorassembler) transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector assembler example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\n",
      "+-----------------------+-------+\n",
      "|features               |clicked|\n",
      "+-----------------------+-------+\n",
      "|[18.0,1.0,0.0,10.0,0.5]|1.0    |\n",
      "+-----------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "dataset = spark.createDataFrame(\n",
    "    [(0, 18, 1.0, Vectors.dense([0.0, 10.0, 0.5]), 1.0)],\n",
    "    [\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\"])\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"hour\", \"mobile\", \"userFeatures\"],outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(dataset)\n",
    "print(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")\n",
    "output.select(\"features\", \"clicked\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d779dc852a40f7ac15d24083cc86a5c",
     "grade": false,
     "grade_id": "cell-72faf34acdca3bb4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feature_assemble(df, featureCols):\n",
    "    \"\"\"\n",
    "    Assemble all features in the featureCols list into one column called 'features'.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    assembler = VectorAssembler(inputCols=featureCols,outputCol=\"features\")\n",
    "    output = assembler.transform(df)\n",
    "    print(\"Assembled columns->\" ,featureCols, \"to vector column 'features'\")\n",
    "    output.select(\"features\").show(truncate=False)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23b7efe52dcc5aeeac6114d27641f39c",
     "grade": true,
     "grade_id": "cell-7ad37566eead3ab5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled columns-> ['Pclass', 'SibSp', 'Parch'] to vector column 'features'\n",
      "+-------------+\n",
      "|features     |\n",
      "+-------------+\n",
      "|[3.0,1.0,0.0]|\n",
      "|[1.0,1.0,0.0]|\n",
      "|[3.0,0.0,0.0]|\n",
      "|[1.0,1.0,0.0]|\n",
      "|[3.0,0.0,0.0]|\n",
      "|[3.0,0.0,0.0]|\n",
      "|[1.0,0.0,0.0]|\n",
      "|[3.0,3.0,1.0]|\n",
      "|[3.0,0.0,2.0]|\n",
      "|[2.0,1.0,0.0]|\n",
      "|[3.0,1.0,1.0]|\n",
      "|[1.0,0.0,0.0]|\n",
      "|[3.0,0.0,0.0]|\n",
      "|[3.0,1.0,5.0]|\n",
      "|[3.0,0.0,0.0]|\n",
      "|[2.0,0.0,0.0]|\n",
      "|[3.0,4.0,1.0]|\n",
      "|[2.0,0.0,0.0]|\n",
      "|[3.0,1.0,0.0]|\n",
      "|[3.0,0.0,0.0]|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "2 points\n",
    "\"\"\"\n",
    "result = feature_assemble(data, ['Pclass', 'SibSp', 'Parch'])\n",
    "assert 'features' in result.columns\n",
    "assert result.schema['features'].simpleString() == 'features:vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c5df23e64ef240fbe5fb092a63cedf7",
     "grade": false,
     "grade_id": "cell-e0d94dd8381cf171",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### All the data preparation has been made. After running the following cell, we can concentrate on running ML modelling.\n",
    "\n",
    "For comparison purposes, let's try a Logistic Regression from MLlib and ML on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec8b4ddc9e87222209060ae5d0d05cdd",
     "grade": false,
     "grade_id": "cell-383133b054ab86e8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|null|    0|    0| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|30.0708|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|   16.7|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|  26.55|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5| 31.275|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0| 7.8542|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|   16.0|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1| 29.125|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|   13.0|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|  7.225|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "<class 'list'>\n",
      "mean value of Age 29.69911764705882\n",
      "+--------+------+--------------------+------+-----------------+-----+-----+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex|              Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+-----------------+-----+-----+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|30.0708|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female|              4.0|    1|    1|   16.7|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|             58.0|    0|    0|  26.55|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|             20.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|             39.0|    1|    5| 31.275|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|             14.0|    0|    0| 7.8542|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|             55.0|    0|    0|   16.0|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male|              2.0|    4|    1| 29.125|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male|29.69911764705882|    0|    0|   13.0|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|             31.0|    1|    0|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|29.69911764705882|    0|    0|  7.225|       C|\n",
      "+--------+------+--------------------+------+-----------------+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Embarked counts before Na removal -> [Row(Embarked='Q', count=77), Row(Embarked=None, count=2), Row(Embarked='C', count=168), Row(Embarked='S', count=644)]\n",
      "value, max_count -> S 644\n",
      "Embarked counts after Na removal -> [Row(Embarked='Q', count=77), Row(Embarked='C', count=168), Row(Embarked='S', count=646)]\n",
      "+--------+-----------------+-------------+-------------+--------------+\n",
      "|Survived|              Age|       SexVec|  EmbarkedVec|   CivilityVec|\n",
      "+--------+-----------------+-------------+-------------+--------------+\n",
      "|       0|             22.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       1|             38.0|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "|       1|             26.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|             35.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       0|             35.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|29.69911764705882|(1,[0],[1.0])|(3,[2],[1.0])|(17,[0],[1.0])|\n",
      "|       0|             54.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|              2.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[3],[1.0])|\n",
      "|       1|             27.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       1|             14.0|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "|       1|              4.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|             58.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       0|             20.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|             39.0|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|             14.0|    (1,[],[])|(3,[0],[1.0])|(17,[1],[1.0])|\n",
      "|       1|             55.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       0|              2.0|(1,[0],[1.0])|(3,[2],[1.0])|(17,[3],[1.0])|\n",
      "|       1|29.69911764705882|(1,[0],[1.0])|(3,[0],[1.0])|(17,[0],[1.0])|\n",
      "|       0|             31.0|    (1,[],[])|(3,[0],[1.0])|(17,[2],[1.0])|\n",
      "|       1|29.69911764705882|    (1,[],[])|(3,[1],[1.0])|(17,[2],[1.0])|\n",
      "+--------+-----------------+-------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Assembled columns-> ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'SexVec', 'CivilityVec', 'EmbarkedVec'] to vector column 'features'\n",
      "+--------------------------------------------------------------+\n",
      "|features                                                      |\n",
      "+--------------------------------------------------------------+\n",
      "|(26,[0,1,2,4,5,6,23],[3.0,22.0,1.0,7.25,1.0,1.0,1.0])         |\n",
      "|(26,[0,1,2,4,8,24],[1.0,38.0,1.0,71.2833,1.0,1.0])            |\n",
      "|(26,[0,1,4,7,23],[3.0,26.0,7.925,1.0,1.0])                    |\n",
      "|(26,[0,1,2,4,8,23],[1.0,35.0,1.0,53.1,1.0,1.0])               |\n",
      "|(26,[0,1,4,5,6,23],[3.0,35.0,8.05,1.0,1.0,1.0])               |\n",
      "|(26,[0,1,4,5,6,25],[3.0,29.69911764705882,8.4583,1.0,1.0,1.0])|\n",
      "|(26,[0,1,4,5,6,23],[1.0,54.0,51.8625,1.0,1.0,1.0])            |\n",
      "|(26,[0,1,2,3,4,5,9,23],[3.0,2.0,3.0,1.0,21.075,1.0,1.0,1.0])  |\n",
      "|(26,[0,1,3,4,8,23],[3.0,27.0,2.0,11.1333,1.0,1.0])            |\n",
      "|(26,[0,1,2,4,8,24],[2.0,14.0,1.0,30.0708,1.0,1.0])            |\n",
      "|(26,[0,1,2,3,4,7,23],[3.0,4.0,1.0,1.0,16.7,1.0,1.0])          |\n",
      "|(26,[0,1,4,7,23],[1.0,58.0,26.55,1.0,1.0])                    |\n",
      "|(26,[0,1,4,5,6,23],[3.0,20.0,8.05,1.0,1.0,1.0])               |\n",
      "|(26,[0,1,2,3,4,5,6,23],[3.0,39.0,1.0,5.0,31.275,1.0,1.0,1.0]) |\n",
      "|(26,[0,1,4,7,23],[3.0,14.0,7.8542,1.0,1.0])                   |\n",
      "|(26,[0,1,4,8,23],[2.0,55.0,16.0,1.0,1.0])                     |\n",
      "|(26,[0,1,2,3,4,5,9,25],[3.0,2.0,4.0,1.0,29.125,1.0,1.0,1.0])  |\n",
      "|(26,[0,1,4,5,6,23],[2.0,29.69911764705882,13.0,1.0,1.0,1.0])  |\n",
      "|(26,[0,1,2,4,8,23],[3.0,31.0,1.0,18.0,1.0,1.0])               |\n",
      "|(26,[0,1,4,8,24],[3.0,29.69911764705882,7.225,1.0,1.0])       |\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, features: vector]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the data !\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'SexVec', 'CivilityVec', 'EmbarkedVec']\n",
    "prepared_data = feature_assemble(one_hot_encode(extract_civility(replace_na(data))), features)\n",
    "prepared_data = prepared_data.withColumnRenamed(\"Survived\", \"label\").select(['label', 'features'])\n",
    "train, test = prepared_data.randomSplit([0.75, 0.25], 0)\n",
    "\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------------------+\n",
      "|label|features                                                                 |\n",
      "+-----+-------------------------------------------------------------------------+\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[1.0,52.0,1.0,1.0,79.65,1.0,1.0,1.0])             |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[1.0,64.0,1.0,4.0,263.0,1.0,1.0,1.0])             |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[2.0,19.0,1.0,1.0,36.75,1.0,1.0,1.0])             |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[2.0,23.0,2.0,1.0,11.5,1.0,1.0,1.0])              |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[2.0,31.0,1.0,1.0,26.25,1.0,1.0,1.0])             |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[2.0,36.0,1.0,2.0,27.75,1.0,1.0,1.0])             |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[2.0,43.0,1.0,1.0,26.25,1.0,1.0,1.0])             |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[2.0,60.0,1.0,1.0,39.0,1.0,1.0,1.0])              |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,14.0,4.0,1.0,39.6875,1.0,1.0,1.0])           |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,14.0,5.0,2.0,46.9,1.0,1.0,1.0])              |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,16.0,1.0,1.0,20.25,1.0,1.0,1.0])             |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,16.0,1.0,3.0,34.375,1.0,1.0,1.0])            |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,16.0,4.0,1.0,39.6875,1.0,1.0,1.0])           |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,18.0,1.0,1.0,7.8542,1.0,1.0,1.0])            |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,18.0,1.0,1.0,20.2125,1.0,1.0,1.0])           |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,26.0,1.0,2.0,20.575,1.0,1.0,1.0])            |\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,29.69911764705882,1.0,2.0,23.45,1.0,1.0,1.0])|\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,29.69911764705882,8.0,2.0,69.55,1.0,1.0,1.0])|\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,29.69911764705882,8.0,2.0,69.55,1.0,1.0,1.0])|\n",
      "|0    |(26,[0,1,2,3,4,5,6,23],[3.0,34.0,1.0,1.0,14.4,1.0,1.0,1.0])              |\n",
      "+-----+-------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d6bb29333c6f86662eec9374a4ca529",
     "grade": false,
     "grade_id": "cell-e455c33086cadefb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## MLlib - RDD based API\n",
    "\n",
    "We will first use the RDD-based [Logistic Regression](https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression). The exercise comes into two steps :\n",
    "\n",
    "1. First, you must create a RDD of LabeledPoint(label, features). Also careful as we are using `pyspark.ml.linalg.SparseVector` but the RDD-based API expects `pyspark.mllib.linalg.SparseVector`, so we need to [convert it](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=linearregressionwithsgd#pyspark.mllib.linalg.Vectors.fromML).\n",
    "2. Then you can apply LogisticRegression on it.\n",
    "\n",
    "# Question\n",
    "\n",
    "Train a logistic regression model on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ea1f00a84a090feaff75579223363b3",
     "grade": false,
     "grade_id": "cell-3d344e0fc760f3e0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def dataframe_to_labeledpoints(df):\n",
    "    \"\"\"\n",
    "    This function takes the conversion from a DataFrame of columns [label, features] to a \n",
    "    RDD of LabeledPoint.    \n",
    "    \"\"\"\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    from pyspark.mllib.linalg import Vectors\n",
    "    \n",
    "    return df.rdd.map(lambda row: LabeledPoint(row[0], Vectors.fromML(row[1])))\n",
    "\n",
    "def train_mllib_logistic(train):\n",
    "    \"\"\"\n",
    "    Return a MLlib logistic regression trained on a RDD of LabeledPoint. \n",
    "    \"\"\"    \n",
    "    # Build the model\n",
    "    model = LogisticRegressionWithLBFGS.train(train)\n",
    "    #model = LinearRegressionWithSGD.train(PipelinedRDD, iterations=100, step=0.00000001)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a57929d658b4020e0f06871602d04b41",
     "grade": true,
     "grade_id": "cell-b54449b3f1087da2",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "train_rdd = dataframe_to_labeledpoints(train)\n",
    "test_rdd = dataframe_to_labeledpoints(test)\n",
    "model = train_mllib_logistic(train_rdd)\n",
    "\n",
    "predictionAndLabels = test_rdd.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "assert metrics.areaUnderROC > 0.75  # I managed ~0.8 on my first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043478260869564"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c51bd15ed342f964c8419cce9892b37",
     "grade": false,
     "grade_id": "cell-0967807fd54e6521",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## ML - DataFrame based API\n",
    "\n",
    "We now compare with using the ML [Logistic regression](https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#binomial-logistic-regression). It should work directly on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8261937d04d9a450c5251a2ee9eed67d",
     "grade": false,
     "grade_id": "cell-50cb55db71381eac",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_ml_logistic(train):\n",
    "    \"\"\"\n",
    "    Return a MLlib logistic regression trained on a RDD of LabeledPoint. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "    lrModel = lr.fit(train)\n",
    "    \n",
    "    # Print the coefficients and intercept for logistic regression\n",
    "    print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "    print(\"Intercept: \" + str(lrModel.intercept))\n",
    "    \n",
    "    return lrModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7def0348bf2f0ec5fa448f9093668879",
     "grade": true,
     "grade_id": "cell-2cb2116413925f78",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (26,[5,6],[-0.06631722609963366,-0.06586495461998135])\n",
      "Intercept: -0.41982427590474464\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "model = train_ml_logistic(train)\n",
    "assert model.summary.areaUnderROC > 0.75 # managed 0.87 on my first try\n",
    "\n",
    "predictions = model.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "assert evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"}) > 0.75 # managed 0.88 on my first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8251811594202898"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce916c26c6d960dbca976554f0a31bba",
     "grade": false,
     "grade_id": "cell-cc43fdd28fe66f9b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
